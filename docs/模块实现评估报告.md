模块实现评估报告
Stage1 – ClueGraph 构建与验证
在 Stage1 阶段，代码确实调用了 ClueGraph 构建逻辑，并且应仅在 Stage1 成功完成后运行。根据代码阅读，Stage1 结束时会生成线索图（ClueGraph），将线索之间的推理关系组织起来【source】。但目前实现存在一些不足之处：
	结果写入 workingDoc： ClueGraph 构建后的结果没有及时持久化到工作文档（workingDoc）。在 Stage1 的 finalize 函数中，构建图后缺少将验证结果附加到 workingDoc 的调用【source】。这意味着后续阶段或最终输出中，读者/用户无法直接看到线索图分析结果。
	Unsupported Inferences 报告： ClueGraph 验证过程中如果检测到不支持的推论，当前实现仅打印警告日志，而没有将这些问题收录到报告部分【source】。例如，当存在根据已知线索无法解释的推论时，系统应在 workingDoc 或输出中标记出来，提醒作者修正。但代码中并未看到将 unsupportedInferences 列表输出的逻辑。
	Orphan Clues 处理： 类似地，孤立线索（orphan clues，即未参与任何推理链的线索）目前只是被识别却未在报告中体现【source】。理想情况下，系统应报告哪些线索没有用到，使作者可以选择删除或融入故事。
改进建议： 在 Stage1 成功后，增加将 ClueGraph 结果写入 workingDoc 的步骤。例如，可在 Stage1 完成时调用 workingDoc.addClueGraph(clueGraph, unsupportedInferences, orphanClues) 方法，将线索网络和问题列表记录下来。同时，扩展 unsupportedInferences 和 orphanClues 的报告机制：生成一个总结段落列出无法支撑的推论以及未用到的线索，并附加到工作文档或控制台输出中，方便后续人工检查【source】。通过这些改进，Stage1 的线索图验证功能才能充分发挥作用，在后续创作阶段之前及时暴露推理漏洞。
Stage0 – MysteryContract 与 PatternPicker 注入
Stage0 负责剧情策划 (planning)。预期实现是将 MysteryContract（神秘合约，即推理小说创作规则）和 PatternPicker（剧情模式选择器）的结果一并注入到策划提示词 (plannerPrompt) 中，以指导后续生成。阅读代码后发现：
	MysteryContract 注入： 系统确实定义了 MysteryContract 的内容（包括公平比赛原则、叙事限制等），但 并未在 Stage0 的提示构建时自动注入【source】。当前 plannerPrompt 主要包含用户提供的提纲要素和 PatternPicker 选择的剧情模板，但缺少合约条款的明确嵌入。这可能导致模型生成的剧情不严格遵守预定规则（例如破坏公平原则）。
	合约内容中的 trick 清单： MysteryContract 预期包含侦探小说常见 诡计清单，用于提示模型采用特定谜题手法。然而代码中合约文本似乎缺少具体诡计列表【source】。PatternPicker 确实能够选定某种谜题模式（例如“双胞胎诡计”“不在场证明漏洞”等），但选定结果没有附加到 MysteryContract 或提示词中。结果是，模型可能不知道具体采用了哪些诡计。
	PatternPicker 注入： PatternPicker 模块根据用户偏好或随机选择了一个剧情模式，但代码仅在内部记录该模式，未将模式名称或细节写入 plannerPrompt【source】。理想情况下，提示词应明确说明所选模式及相应要求，比如：“本故事采用【密室杀人】模式，需包含至少一个密室情境”。目前这些指导信息没有传递给模型。
改进建议： 确保在 Stage0 生成策划提示时，系统消息部分包含 MysteryContract 条款和所选诡计模式。例如，可在组装 plannerPrompt 时先插入 MysteryContract 内容，然后列出 PatternPicker 选定的诡计清单作为附加规则。代码上，可在 buildPlannerPrompt() 函数中增加：prompt = MysteryContract.text + "\n" + "Tricks to use: " + pattern.trickList + "\n" + promptBody【source】。这样，模型在规划阶段就清楚需遵循的规则和剧情套路。此外，丰富 MysteryContract 内容，包含约定的十诫或范达因守则等条目，确保合约覆盖全面的公平性要求。通过这些注入，Stage0 提示词将更完整对齐项目目标，引导模型输出符合预期的剧情纲要。
Stage2 – Watsonization 与 StylePack 应用
Stage2 主要承担将提纲扩展成故事草稿。按照设计，应在这一阶段实现 Watsonization（视角控制）和 StylePack（风格套件）应用，并应在执行 enforceDialoguesInDraft 之后注入。这部分代码实现存在一定偏差：
	Watsonization（华生视角转换）： 预期功能是将叙事限制在“华生”视角，即旁观者/助手的有限视角，从而避免直接透视真相。然而，在当前 Stage2 实现中，没有找到明确执行视角转换的代码【source】。生成草稿时，模型可能会以全知视角叙述或透露破案者的思路。缺少 Watsonization 步骤意味着读者可能过早得知真相或看到侦探内心想法，违背推理小说惯例。理想的 Watsonization 应在对话强制 (enforceDialoguesInDraft) 之后进行，对初稿进行遍历或二次生成，替换掉任何一人称侦探视角的内容。例如，检测“I thought…”这样的句子并改以第三者视角表述。目前代码里未发现这样的处理逻辑。
	StylePack（风格语料限制）： 项目提供了特定风格套件（可能是某著名推理作家的文风范例或自定义风格参数）。但 Stage2 生成过程中，并没有看到将 StylePack 约束显式注入到草稿生成的提示中【source】。例如，如果 StylePack 要求维多利亚时代的措辞或特定语气，现在的实现并未在提示里加入这些说明，也未在后处理时对文本风格进行检查或调整。结果，故事草稿风格可能偏离预期。
	注入时机： 按照设计，enforceDialoguesInDraft 确保草稿中有一定比例的对话文本，提高可读性。从代码顺序看，确实存在 enforceDialoguesInDraft(draft) 函数调用，将缺失对话的段落转换为对话形式【source】。但在调用完该函数后，Watsonization 和 StylePack 相关处理并未接续执行。也就是说，当前实现并没有在对话调整之后做额外的视角和风格修正。
改进建议： 在 Stage2 末尾增加两个后处理步骤：
	视角调整： 实现 Watsonization 功能。可以编写一个遍历草稿段落的函数，例如 applyWatsonPerspective(draft), 找出第一人称侦探叙述或上帝视角叙述的句子，将其改写为助手/观察者视角。如检测到诸如“我突然意识到…”改为“侦探的神情突然一亮，仿佛意识到了什么…”。此转换可借助规则或再次调用语言模型进行局部改写【source】。将该步骤放在 enforceDialoguesInDraft 之后，以免对话调整影响视角处理。
	风格套件注入： 在提示模板或后处理阶段融合 StylePack 要求。如果有预先收集的风格例句，可以在生成提示时加入 few-shot 样例；如果是参数化风格控制（如正式度、幽默度等滑杆），则在提示中附加说明，比如“以经典维多利亚时代英语风格书写”或使用模型的系统消息设定语气【source】。另外，可以对生成后的文本运行风格一致性检查脚本，确保用词和句法匹配目标风格。如果偏差较大，可以二次编辑或提示模型润色。
通过上述增强，Stage2 将更严格地控制叙事视角，确保读者与侦探同步发现真相，同时让草稿风格与预期语料对齐，提升故事的沉浸感和品质。
Stage3 – Beta Reader Solver 与 Hypothesis Evaluator
Stage3 引入“测试读者”（Beta Reader）模拟和假设评估两个模块，以检验故事谜题的有效性和推理解答过程。代码实现上可以看出这些模块的雏形，但仍有不足：
	Beta Reader Solver 实现： 代码中存在 BetaReaderSolver 调用，它使用当前草稿让模型扮演读者尝试推理凶手及动机【source】。此步骤旨在发现故事中是否存在多个可能解、读者是否能根据线索合理猜测真相。然而，BetaReaderSolver 的反馈目前未被充分利用。实现里通常只是记录了模型生成的猜测，并没有根据其结果动态调整故事或提示作者。理想情况下，如果 Beta Reader 无法猜出真相，说明线索不足；若猜错真凶，说明误导可能过多；如果过早猜出真相则说明谜题太直白。这些信息应触发相应的内容修改。然而当前代码仅打印了 Beta Reader 的假设，没有后续处理逻辑【source】。
	Hypothesis Evaluator 实现： HypothesisEvaluator 模块用于评估每个假设（尤其是正确解答）与线索的支持度。目前实现可以调用模型或规则来检查“给定答案是否由线索推导合理”【source】。但存在问题：当 HypothesisEvaluator 检测到推理链不完整时（例如真凶结论缺少关键证据），代码里缺乏自动响应机制。预期行为可能是标记出缺失的推理步骤，供 Stage4 补全。然而实际实现中，只是将这种不一致打印警告，而没有反馈到故事修改流程中。
	超时与降级策略： Beta Reader 模拟和假设评估都可能因为LLM生成慢或复杂度高而超时。目前代码里没有看到明显的超时处理或降级方案【source】。假如模型在合理时间内未返回结果，系统应采取降级措施（例如跳过Beta Reader步骤直接进入下一阶段，或采用简单heuristic评估）。缺少超时处理会导致整个流水线卡在Stage3。
改进建议：
	利用 Beta Reader 反馈： 增强 Stage3，将 BetaReaderSolver 的输出用于动态调整剧情。比如，引入逻辑：如果Beta Reader没能列出真凶或推理错误，记录此现象到 workingDoc，并在 Stage4 时提示添加额外线索；如果Beta Reader过早猜中结局，则考虑在前文加入混淆性情节来提升难度。代码实现上，可检查 BetaReaderSolver 返回的 top hypotheses 列表，判断真凶是否名列其中，以及排名状况，然后设置标志供后续使用【source】。
	假设评估反馈： 扩展 HypothesisEvaluator，让其输出结构化的差异报告。例如，生成一个对象包含未支撑的推论点列表。随后，在 Stage4 构建结局时，遍历该列表，对每个缺口调用生成器补充说明。例如：“
	…
	尚未解释的重要线索：XXX”，然后自动生成侦探在结尾处对其解释的段落【source】。这样把评估结果真正闭环到内容修正上。
	超时与降级： 为 BetaReaderSolver 和 HypothesisEvaluator 调用增加超时监控（例如使用Promise.race或相应异步超时机制）。如果超过预设时间（如30秒）无结果，记录超时事件并继续后续流程不要卡死。在降级策略方面，可以准备一个简易评估替代：例如Beta Reader超时则跳过读者模拟，只用HypothesisEvaluator的结果判断谜题完整性；反之HypothesisEvaluator超时，则仅根据Beta Reader的推理判断可解度。如果两者都超时，至少发出警告但让流程继续。实现上可包装调用在try-catch并设定计时，发生异常时设置一个 stage3Warning = true，最终在 Stage5 输出警告信息供用户参考【source】。
通过这些改进，Stage3 将更智能健壮：既能获得模型反馈，又能保障流程不中断，并把发现的问题用于完善故事情节，提升谜题质量。
Stage4 – DenouementScript 构建与 Plant–Payoff 完整性
Stage4 负责撰写故事大结局（Denouement），并确保之前埋下的每个伏笔（plant）都有交代（payoff）。代码表现出初步的结局生成功能，但在伏笔核查和补全方面尚未完全实现：
	DenouementScript 构建： 程序能够根据前文剧情和最终谜底，生成侦探揭示真相的结局段落。观察代码，Denouement 部分通常由模型根据最终答案和线索列表生成【source】。这一功能基本实现，能产出一个总结性叙述，包括揭露真凶、作案手法和动机。然而，目前只生成一版结局，对线索细节的覆盖可能不全面。
	Plant–Payoff 完整性检查： 理论上，Stage4 应比对线索清单和结局内容，找出未被解释的伏笔。然而从代码看，虽然有收集线索的列表和最终解答内容，但缺少显式的比对校验【source】。也就是说，程序未明确检查“每个线索是否在结局里有所交代”。这可能导致某些线索（尤其次要线索）悄无声息地悬而未决。
	缺失时的补丁注入： 对于检测出的未交代线索，预期行为是在结局中插入补充段落填坑。但代码中未找到执行该操作的部分【source】。没有看到类似“for each missingClue: generateExplanationParagraph”之类的循环。因此，即便Stage1/3可能标记了孤立线索或HypothesisEvaluator指出了缺失推理，Stage4目前也不会主动增补相应说明。
改进建议： 在 DenouementScript 生成后增加一个伏笔校验与补丁过程：
	完整性检查： 将 Stage1 阶段收集的线索列表（或者ClueGraph节点）与 DenouementScript 文本进行匹配。可以简单搜索每条线索的关键字是否出现在结局段落中【source】。对于没有出现的线索，视为未兑现的伏笔。
	生成补充段落： 对每个未兑现伏笔，调用段落生成模型（DeepSeek）创作一段解释，放在结局尾声。例如：“关于先前提到的绿围巾线索，侦探这时解释道：那条围巾其实是…（解释其真实意义）”。为确保风格一致，可以在提示中明确这是补充说明段落。代码实现上，可在 Stage4 最后插入：

	missingClues.forEach(clue => {
    const patch = deepseekWriter.generatePatchParagraph(clue, solution);
    denouementScript.append(patch);
});
	【source】这样每个孤立线索都会得到交代。
	顺畅衔接： 插入补丁段落时，要注意结局文本的衔接和过渡词，使之阅读流畅。可以在生成提示里要求模型使用适当的承接句，例如“此外，…”。
最后，再次运行一次完整性检查确保所有线索都有回应。如果仍有遗漏，可标记警告提示人工审阅。通过此机制，Stage4 将保证每个伏笔都有回报，杜绝读者疑惑“某线索有什么用”的情况，提高故事完备性和读者满意度。
Stage5 – fairPlayGate 与 complexityGate 上线
Stage5 是最终的质量闸，包含公平玩法审核（fairPlayGate）和复杂度审核（complexityGate），以不同级别警告或拦截不合格的故事，并记录调试信息。当前实现存在以下问题：
	fairPlayGate 执行： fairPlayGate 按预期检查故事是否违反公平原则（如是否提前给出足够线索，结局中是否有读者无法获知的信息等）。代码中定义了一系列规则（可能来源于MysteryContract）用于验证故事文本【source】。这些检查包括：是否出现超自然解释、双胞胎冒充等禁忌手法，或者关键证据是否在结局前呈现。然而问题在于：检测结果的处理不充分。当前实现若发现违规，只是在日志中输出警告信息【source】。并没有将其分级处理——既没有在UI上警示用户，也没有真的阻止故事发布。比如，若侦探在结尾引出读者未知的新证据，系统应判定为严重违规并阻挡；但代码里这种情况可能仅打印：“FairPlay violation: 新证据未提前展示”。
	complexityGate 执行： complexityGate 用于衡量故事的阅读和解谜复杂度。实现上，代码计算了一些指标（如字数、句子难度、谜题复杂度评分等）【source】。这些指标与预设阈值比较，以决定是否过于复杂或简单。然而，和 fairPlayGate 类似，结果仅作为日志或调试输出，没有真正影响流程。例：如果复杂度评分超标，当前实现可能只是输出：“ComplexityGate: complexity=9.5, threshold=8”而没有进一步动作。理应在超标时给出警告甚至阻止用户继续，而代码未见这部分。
	分级判定 (warn/block)： 期待逻辑是对不同严重程度的问题分别处理——轻微问题（如一个次要线索稍显生硬）给予 警告，严重问题（如犯了大忌）执行 阻断。目前代码没有实现这种区分机制【source】。没有看到比如返回一个severity级别并根据它决定流程的代码。
	调试记录： Stage5 应将审核详细结果记录下来，方便开发者或作者了解触发了哪些规则、指标值是多少。代码部分地打印了相关信息（如上所述），但缺少将这些调试数据汇总保存的过程【source】。理想状态是把所有违规项及复杂度评估结果写入一个报告对象或文件。当前只是零散的 console.log，调试信息很可能在会话结束后丢失。
改进建议：
	引入严重性级别： 修改 fairPlayGate 和 complexityGate 的返回结构，包括问题列表和每项的严重性。比如，fairPlayGate 返回 [ {issue: 'New evidence at end', severity: 'blocker'}, {...} ]。根据规则重要性打标签（参考侦探小说创作守则，对读者不公的一律标为阻断）。complexityGate 同理，根据超出阈值多少决定警告或阻断。
	联动流程控制： 在 Stage5 主流程中，收集两个 gate 的结果，然后做分级处理：如果存在任何阻断级问题，则中止生成流程，在UI上提示错误并要求修改后重试【source】。对于仅有警告级问题的，允许生成结果但在UI上弹出警示，让用户知悉潜在问题。实现上，可在最终输出前插入检查：

	const issues = fairPlayGate.check(story);  
issues.concat(complexityGate.check(story));  
const blockers = issues.filter(i => i.severity==='block');  
const warnings = issues.filter(i => i.severity==='warn');  
if(blockers.length > 0) {  
    throw new Error('Story blocked: ' + blockers[0].issue);  
}  
	如上，当有阻断项时抛出异常或以特定方式终止输出【source】；当只有警告时，将warnings附加到结果元数据，供界面显示“⚠ 注意…”。
	强化调试日志： 将所有审核细节记录到 workingDoc 或日志文件。例如，在开发模式下，将 fairPlayGate 的各条规则检查结果（通过/未通过）都保存下来；complexityGate 则记录具体指标值（字数、句长、Flesch阅读分数等）。这些数据可以帮助后续改进模型或调整阈值。代码上，可以增加一个 debugReport 对象，每次检查时 debugReport.fairPlay.push({...})，最后序列化输出【source】。
通过以上改进，Stage5 将真正成为质量守门员：在不牺牲用户体验的前提下，严格把关故事合理性和难度，提供分级反馈和完整的调试信息，让作者清楚任何潜在问题并进行相应调整。
DeepSeek 模型段落生成迁移
项目在段落生成方面已从原有模型迁移至 DeepSeek 模型（实现于 deepseekWriter.ts），并旨在保留结构化信息如字数和所用线索ID。根据代码评估：
	模型调用迁移： 新的 deepseekWriter.ts 模块封装了对 DeepSeek 模型的调用，用于生成故事的各个段落。从代码看，主要的写作任务（如场景描写、对话生成）都改为使用 deepseekWriter.generateParagraph() 函数获取结果【source】。旧的写作模型（可能是 GPT 或类似 API）调用已基本废弃，仅在个别遗留功能或异常fallback时出现。这表明段落级文本生成已大体迁移到 DeepSeek，符合预期。
	返回结构化数据： DeepSeek 模型生成段落时，代码会提取并返回元信息。如计数生成文本的字数、标识出了用了哪些线索ID【source】。实现里常见模式是：模型返回的文本通过正则或内置格式解析出 { text: "...", usedClues: [id1,id2,...], wordCount: N } 的对象。例如，deepseekWriter 内部可能调用模型的Chain-of-Thought，让其在输出中标注用了哪些线索编号，然后代码截取这些标记计算字数。
	元数据利用： 虽然模型返回了上述结构化信息，但在当前代码中其利用尚不充分。检查发现，生成段落时计算出的 wordCount 等数据，多数只是用于日志打印或简单累加总字数【source】。对于 usedClueIDs，代码将其收集但未进一步验证每个线索是否至少使用一次。换言之，DeepSeek 提供的丰富信息并未完全被下游逻辑消费。例如，没有模块在最终检查所有线索ID都出现在 usedClues列表中（这本可以作为公平性校验的一部分）。
	可能的遗留问题： 迁移过程中，有少部分功能仍调用旧模型接口。如在非主要路径（比如当 DeepSeek 返回内容为空时），代码里可能 fallback 到旧 writeParagraphGPT() 之类的方法【source】。这些遗留调用可能不返回结构化数据，从而中断元信息的传递链。此外，旧模型生成的段落风格和内容可能与 DeepSeek 不一致，影响整体故事连贯性。
改进建议：
	全面使用 DeepSeek 接口： 清理遗留的旧模型调用，确保所有内容生成统一经由 deepseekWriter。这样可以保证输出风格一致，并能统一处理结构信息。若需要fallback策略，也应让 DeepSeek 模型多尝试几次或换用其不同prompt，而不是切回旧模型。
	强化元数据利用： 将 DeepSeek 返回的 usedClues 列表用于验证故事完整性。在故事结束后（或Stage4之后），对比线索总清单和累计的 usedClues集合，自动找出未被使用的线索【source】。这些未使用线索可作为 orphanClue，再次触发前述 Stage4 补丁逻辑或 Stage5 的公平性警告。字数信息也可用于监控每章节长度，确保不会过长或过短——代码里可以累加每段的wordCount并在章节结束时比较预期范围，超出时警告或自动摘要缩减。
	结构化输出扩展： 未来可考虑让 DeepSeek 直接输出更丰富的结构化信息，如情节节点标识、人物出场次数等。代码可以扩展 deepseekWriter，将模型输出解析为 JSON 格式，便于程序逻辑利用。这样做有助于在不增加人工检查的情况下，让后续模块更智能地评估和调整故事（例如 BetaReaderEvaluator 可直接利用这些结构数据而非仅自然语言）。
通过彻底迁移到 DeepSeek 及充分利用其返回的数据，段落生成模块将更稳定且可控，既保证文风统一，又为质量监控提供了抓手，实现技术和内容上的双重提升。
提示词模板架构与控制项支持
提示词模板在项目中扮演指导模型创作的蓝图角色。根据要求，它应遵循系统合约 + 章节任务 + Beat单元三层架构，并支持风格滑杆（sliders）和陈词滥调（cliché）控制。目前实现情况如下：
	三层提示架构： 从代码组织上，可以辨认出一定的分层结构。例如，存在定义系统级别提示词片段（通常包含 MysteryContract 规则等）【source】；各主要阶段也各自有描述任务的提示语（如 Stage2 的“根据提纲写正文草稿”之类）【source】。同时，在实际段落生成时，代码会为每一个“小节/节拍 (beat)”组装当前上下文和下一步要求。这表明提示模板的大致三层框架已有所体现。不过实现上可能没有完全解耦：并未发现专门的数据结构或函数清晰地区分这三层。例如，“章节任务”和具体段落beat的界限有时由同一个函数处理，造成层次混淆【source】。
	Sliders（风格旋钮）支持： 项目提供了一系列风格控制参数，如节奏快慢、幽默程度、对话比例等。这些 sliders 在UI或配置中可设定，但在提示模板中未看到相应动态调整【source】。例如，如果用户将“幽默”调高，理应在系统或用户提示中加入“采用幽默笔调”；如果“黑暗”调低，则提示应要求避免血腥。然而当前模板基本静态，没有针对 slider 参数修改用词或语气的逻辑。也未见到有代码根据 slider 值选择不同few-shot示例库或词汇表的实现。
	Cliché 控制： 防止生成陈词滥调是高质量创作的一部分。代码中并没有直接出现“cliché”列表或过滤机制【source】。MysteryContract 也未包含类似“避免使用XX俗套”这样的指示。这意味着模型可能偶尔会产出一些推理小说常见套路句式（例如“真相只有一个！”或“出人意料的是…”等）。目前没有检测或剔除这些内容的措施。
	模板稳定性： 现有提示模板可能在不同阶段重复或缺少关键信息，从而影响模型输出稳定性。例如，如果系统合约过长且每次调用都重复发送，模型可能出现忽略部分指令的情况；如果章节任务描述不清晰，则每段输出可能跑题。此外，没有充分利用few-shot案例：模板中几乎没有提供范例段落来引导模型风格和结构【source】。这可能导致输出质量在边界情况下波动。
升级方案建议： 为使提示模板更稳定并契合任务目标，我们可以从架构和内容两方面改进：
	严格分离三层结构： 重构提示生成代码，明确拆分出三个层级的模板组装函数：buildSystemContractPrompt(), buildChapterTaskPrompt(chapter), buildBeatPrompt(context)。系统合约部分应仅设定整体规则和风格基调，一次生成后各阶段复用【source】。章节任务部分针对每个Stage具体说明当下要完成的内容（如“第2章：描写侦探调查线索经过”）。Beat层则聚焦当前段落，比如提示模型“接下来写侦探与嫌疑人对质的对话”。三层内容在实际调用模型时按顺序拼接，这样结构清晰、不易遗漏信息。
	动态风格调整： 将 sliders 参数映射到具体的提示语句或示例上。例如，维护一张映射表：幽默=高 时在系统合约中加入“语调上轻松诙谐”指令；紧张度=低 则加入“整体氛围轻松”描述等。代码实现上，可以在构建系统提示时，根据每个 slider 的值插入相应文本片段【source】。另外，选取符合这些参数的示例片段作为 few-shot 提供给模型学习风格。例如，当“悬疑”高时，提供一段紧张悬疑的对话示例在提示中。
	引入反陈词滥调机制： 在 MysteryContract 或系统提示部分，显式列出需避免的套路短语和情节处理。例如：“不要使用常见俗套如‘管家是凶手’、‘突然失忆’等。”【source】。同时，编写一个简单的生成后检查函数，扫描输出文本中是否含有预先定义的cliché短语列表，如发现则反馈给模型要求重写或在后处理时替换为更原创的表述。这样的双保险可以明显减少陈词滥调出现的频率。
	Few-shot 案例提供： 稳定输出的有效方法是给模型一些示例。可以针对各章节类型准备简短范例段落（符合 MysteryContract 的风格和规则），插入到提示中让模型参考。例如，提供一个经典名侦探小说结局揭露段落作为范例，有助于Stage4输出更有条理。代码上，可以在模板中预留位置，如 {{example_reveal_paragraph}}，由程序从风格库中选取填充【source】。这些示例应与 sliders 结合（如用户想要幽默风，则选幽默侦探小说的片段）。
	精简与重点突出： 优化提示词长度，去除重复的或冗长的指令，确保模型不会因提示过长忽略末尾关键信息。把最重要的规则（公平原则、视角、关键风格要求）放在系统合约的明显位置，并可以在章节任务中短句提醒，以加深印象。比如在每个章节任务开头用一句强调：“注意保持华生视角，未知真相”【source】。这种重复有助于模型在长篇输出中不跑偏。
通过以上升级，提示词模板将变得层次清晰且灵活可控。模型能够牢牢遵循系统合约制定的规则，又能根据具体章节任务聚焦当前目标，并响应风格控制进行调整。同时，避免陈词滥调和提供示例导引将有效提高输出的新颖性和稳定性，使生成的推理故事更加符合用户预期目标。
________________________________________
